{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Семинар 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейная регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поработаем с линейной регрессией на практике с помощью библиотеки [scikit-learn](https://scikit-learn.org/stable/). Эта библиотека включает в себя множество алгоритмов, разные тестовые наборов данных, функции для подсчета метрик и подбора параметров, а также многое другое.\n",
    "\n",
    "Scikit-learn появился как проект David Cournapeau на [Google Summer of Code](https://summerofcode.withgoogle.com/). Позднее к проекту присоединились другие разработчики, и первый релиз библиотеки состоялся 1 февраля 2010 года. Она быстро стала популярной засчет большого количества алгоритмов и простоты использования. Библиотека sklearn полезна для экспериментов, написания быстрых прототипов, участия в соревнованиях по анализу данных и во множестве других приложения. В тоже время, для промышленных проектов она может не подходить ввиду неоптимизированного кода и выбранного языка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (11.5, 8.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "96iNvJn-28j4"
   },
   "source": [
    "## Данные\n",
    "Для демонстраций загрузим набор данных [Automobile Data Set](https://archive.ics.uci.edu/ml/datasets/Automobile). В данных присутствуют категориальные, целочисленные и вещественнозначные признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u30Ou_XY28j5"
   },
   "outputs": [],
   "source": [
    "X_raw = pd.read_csv('automobiles.csv', na_values=[\"?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "U3zLI-Jd28j8",
    "outputId": "73e6c0e3-f3a7-4128-cb8b-6c7f66138c00"
   },
   "outputs": [],
   "source": [
    "X_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xHXo8yny28j_"
   },
   "outputs": [],
   "source": [
    "y = X_raw['price']\n",
    "X_raw = X_raw.drop('price', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7RLJ_PH928kC"
   },
   "source": [
    "## Предобработка данных\n",
    "Предобработка данных важна при применении любых методов машинного обучения, а в особенности для линейных моделей. В sklearn предобработку удобно делать с помощью различных модулей (например, [preprocessing](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing)) или методов библиотеки pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8OIYuChq28kH"
   },
   "source": [
    "### Заполнение пропусков\n",
    "В матрице объекты-признаки могут быть пропущенные значения, и это вызовет ошибку при попытке передать такую матрицу в функцию обучения модели или даже предобработки. Если пропусков немного, можно удалить объекты с пропусками из обучающей выборки. Заполнить пропуски можно [разными способами](https://scikit-learn.org/stable/modules/impute.html), например:\n",
    "\n",
    "* заполнить средними (mean, median);\n",
    "* предсказывать пропущенные значения по непропущенным.\n",
    "\n",
    "Последний вариант сложный и применяется редко. Для заполнения константами можно использовать метод датафрейма `fillna`, для замены средними - класс [`impute.SimpleImputer`](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html) (в более старых версиях `scikit-learn` - `preprocessing.Imputer`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим пример его работы (из документации)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "array1 = np.array([[7, 2, 3], [4, np.nan, 6], [10, 5, 9]])\n",
    "array1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array2 = np.array([[np.nan, 2, 3], [4, np.nan, 6], [10, np.nan, 9]])\n",
    "array2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_mean.transform(array2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_mean.fit(array1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_mean.transform(array2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_mean.fit_transform(array1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вернемся к нашим данным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_5bbvMK828kH"
   },
   "outputs": [],
   "source": [
    "# для удобства работы с нашим датасетом создаем маску, указывающую на столбцы с категориальными признаками\n",
    "cat_features_mask = (X_raw.dtypes == \"object\").values # категориальные признаки имеют тип \"object\"\n",
    "cat_features_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "id": "zjYtWWxQ28kK",
    "outputId": "e36cfd77-b941-437a-c3c6-fbe09d606743"
   },
   "outputs": [],
   "source": [
    "# для вещественнозначных признаков заполним пропуски средними значениями\n",
    "X_real = X_raw[X_raw.columns[~cat_features_mask]]\n",
    "mis_replacer = SimpleImputer(strategy=\"mean\")\n",
    "X_no_nans_real = pd.DataFrame(data=mis_replacer.fit_transform(X_real), columns=X_real.columns)\n",
    "# для категориальных - пустыми строками\n",
    "X_cat = X_raw[X_raw.columns[cat_features_mask]].fillna(\"\")\n",
    "X_no_nans = pd.concat([X_no_nans_real, X_cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "H34gZsTX28kN",
    "outputId": "52d9cdaa-86f1-44e2-91d7-75310c6e1045"
   },
   "outputs": [],
   "source": [
    "X_no_nans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_no_nans.isnull().any().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ux1uxDgK28kQ"
   },
   "source": [
    "Всегда нужно осознавать, случайны ли пропуски в каком-то признаке. Иногда факт отсутствия информации о значении признака может сам быть важным признаком, который необходимо добавить к другим признакам.\n",
    "\n",
    "__Пример:__ предсказание возраста пользователя по данным с его телефона. Поскольку люди старшего возраста чаще пользуются простыми телефонами, факт отсутствия каких-то данных (например, истории посещенных интернет-страниц), скорее всего, будет хорошим признаком.\n",
    "\n",
    "Для категориальных признаков рекомендуется создавать отдельную категорию, соответствующую пропущенному значению."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fNoCS3EK28kR"
   },
   "source": [
    "### Преобразование нечисловых признаков\n",
    "Практически все методы машинного обучения требуют, чтобы на вход функции обучения подавалась вещественная матрица. В процессе обучения используются свойства вещественных чисел, в частности, возможность сравнения и применения арифметических операций. Поэтому, даже если формально в матрице объекты-признаки записаны числовые значения, нужно всегда анализировать, можно ли относиться к ним как к числам. \n",
    "\n",
    "__Пример:__ некоторые признаки могут задаваться целочисленными хешами или id (например, id пользователя соц. сети), однако нельзя сложить двух пользователей и получить третьего, исходя из их id (как это может сделать линейная модель).\n",
    "\n",
    "К категориальным признакам, принимающим значения из неупорядоченного конечного множества $K$, часто применяют [one-hot encoding](http://scikit-learn.org/stable/modules/preprocessing.html#encoding-categorical-features) (вместо одного признака создают $K$ бинарных признаков - по одному на каждое возможное значение исходного признака). Правда, нужно понимать, что создание $K$ таких признаков приведет к [мультиколлинеарности](https://ru.wikipedia.org/wiki/%D0%9C%D1%83%D0%BB%D1%8C%D1%82%D0%B8%D0%BA%D0%BE%D0%BB%D0%BB%D0%B8%D0%BD%D0%B5%D0%B0%D1%80%D0%BD%D0%BE%D1%81%D1%82%D1%8C), и поэтому в зависимости от применяемой модели может быть стоит [убрать один из них](https://stats.stackexchange.com/questions/231285/dropping-one-of-the-columns-when-using-one-hot-encoding) (и оставить $K - 1$ признак).\n",
    "\n",
    "В `sklearn` one-hot кодирование можно сделать с помощью класса [`OneHotEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html), а можно использовать функцию [`pd.get_dummies`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HBmFt92528kS"
   },
   "source": [
    "Следует заметить, что в новой матрице будет очень много нулевых значений. Чтобы не хранить их в памяти, можно задать параметр `OneHotEncoder(sparse=True)` или `.get_dummies(sparse=True)`, и метод вернет [разреженную матрицу](http://docs.scipy.org/doc/scipy/reference/sparse.html), в которой хранятся только ненулевые значения. Выполнение некоторых операций с такой матрицей может быть неэффективным, однако большинство методов sklearn умеют работать с разреженными матрицами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wZxxhNbj28kS"
   },
   "source": [
    "__Вопрос__: стоит ли применять one-hot encoding для признаков с большим числом категорий (например, id)? Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "SqwMFEqt28ka",
    "outputId": "0e63656f-1662-4584-b59c-8719b630a540"
   },
   "outputs": [],
   "source": [
    "X_no_nans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 259
    },
    "colab_type": "code",
    "id": "hLiNNMYz28kc",
    "outputId": "1c3edfb1-699c-420a-9b9b-302682dd7c89"
   },
   "outputs": [],
   "source": [
    "X_dum = pd.get_dummies(X_no_nans, drop_first=True)\n",
    "print(X_dum.shape)\n",
    "X_dum.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BVJEU31i28kf"
   },
   "source": [
    "Помимо категориальных признаков, преобразования требуют, например, строковые признаки. Их можно превращать в матрицу частот слов с помощью [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer), матрицу частот буквосочетаний фиксированной длины, можно извлекать другие признаки (например, длина строки)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IaZ_SxAP28kf"
   },
   "source": [
    "### Масштабирование признаков\n",
    "В ходе предобработки данных часто рекомендуется приводить все признаки к одному масштабу. Это важно по нескольким причинам:\n",
    "\n",
    "* ускорение обучения модели;\n",
    "* улучшение численной устойчивости при работе с матрицей объекты-признаки;\n",
    "* для линейных моделей: интерпретация весов при признаках как меры их значимости.\n",
    "\n",
    "(полезная ссылка: https://towardsdatascience.com/understand-data-normalization-in-machine-learning-8ff3062101f0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BLCmI77c28kg"
   },
   "source": [
    "Первый популярный способ масштабирования - нормализация: вычитание среднего из каждого признака и деление на стандартное отклонение ([`StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) в sklearn). Второй популярный способ: вычитание минимума из каждого признака, а затем деление на разницу максимального и минимального значения ([`MinMaxScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) в sklearn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "3kHPINOO28kk",
    "outputId": "3c72707b-b6e9-49cd-93d2-42aa71c08e02"
   },
   "outputs": [],
   "source": [
    "normalizer = MinMaxScaler()\n",
    "X_real_norm_np = normalizer.fit_transform(X_dum)\n",
    "X = pd.DataFrame(data=X_real_norm_np, columns=X_dum.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dbwg7jRv28kn"
   },
   "source": [
    "### Добавление признаков\n",
    "Особенно важным моментом для линейной регрессии является нелинейное преобразование признаков. Это позволяет использовать линейную регрессию для моделирования нелинейных зависимостей. Из популярных преобразований можно выделить следующие: полиномиальные признаки ([`PolynomialFeatures`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html) в sklearn), взятие логарифма, квадратного корня, применение тригонометрических функий.\n",
    "\n",
    "Например, в нашем датасете зависимость целевой переменной от признака 'curb-weight' скорее квадратичная, чем линейная:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "colab_type": "code",
    "id": "Bv0qZAP028kr",
    "outputId": "768a5478-94b4-4316-e0d4-caa848d526a1"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X['curb-weight'], y)\n",
    "plt.xlabel('curb-weight')\n",
    "plt.ylabel('price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "colab_type": "code",
    "id": "In7bi4a728ku",
    "outputId": "79bde2a7-9957-492b-d9e6-006c697ccad3"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X['curb-weight']**2, y)\n",
    "plt.xlabel('(curb-weight)$^2$')\n",
    "plt.ylabel('price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3LLqJaxF28kw"
   },
   "source": [
    "А для признака 'highway-mpg' линеаризовать зависимость получается с помощью функции $\\frac 1 {\\sqrt{\\cdot}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "colab_type": "code",
    "id": "Ff2MqK_U28kx",
    "outputId": "d661be98-f8da-4e6c-9409-dcdacd19a36e"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X['highway-mpg'], y)\n",
    "plt.xlabel('highway-mpg')\n",
    "plt.ylabel('price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "colab_type": "code",
    "id": "6MhgQI3p28kz",
    "outputId": "52bb321e-55e9-42fb-b407-e3d90e7a2ee8"
   },
   "outputs": [],
   "source": [
    "plt.scatter(1 / np.sqrt(X['highway-mpg']), y)\n",
    "plt.xlabel('$\\\\left(\\sqrt{\\\\mathrm{highway-mpg}}\\\\right)^{-1}$')\n",
    "plt.ylabel('price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C6Qy8_i_28k1"
   },
   "source": [
    "Обратите внимание, что при генерации полиномиальных признаков матрица объекты-признаки может занимать очень много памяти."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nPqAUdTR28k1"
   },
   "source": [
    "## Функции потерь в регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "4nkY6ylA28k2"
   },
   "source": [
    "Функционал качества в задачах обучения с учителем обычно задается в виде суммы по объектам выборки:\n",
    "$$Q(a, X) = \\frac 1 \\ell \\sum_{i=1}^\\ell L(y_i, a(x_i)),$$\n",
    "где $L(\\cdot, \\cdot)$ - функция потерь, задающая штраф за разницу между предсказанием и истинным значением целевого признака."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0tvTz0GJ28k3"
   },
   "source": [
    "Как отмечалось на первой лекции, функционал качества должен в первую очередь отвечать требованиям заказчика, при этом математические свойства функции потерь могут быть неудобны для оптимизации. \n",
    "\n",
    "__Пример:__ если мы не различаем маленькие ошибки (между 0.01 и 0.1 нет особой разницы), но зато не хотим получать большие ошибки, можно использовать следующую функцию потерь:\n",
    "\n",
    "$$L(y_i, a(x_i)) = [| y_i - a(x_i) | < \\varepsilon],$$ $\\varepsilon$ - допустимая разница между предсказанием и правильным ответом.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j-ade-VU28k4"
   },
   "source": [
    "### Среднеквадратичная и средняя абсолютная ошибка\n",
    "Кроме требований заказчика, функционал качества должен учитывать математические особенности модели - например, устойчивость к шумовым объектам. В линейной регрессии функция потерь $L(y_i, a(x_i)) = (a(x_i) - y_i)^2$ не обладает этим свойством, потому что задает очень большие штрафы за большие отклонения от фактического значения. \n",
    "\n",
    "Рассмотрим это явление на примере. Предскажем значения признака 'make_audi' по признаку 'engine-size' с помощью линейной регрессии. Добавим к выборке два объекта-выброса и посмотрим, как изменится оптимальная с точки зрения MSE прямая."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JVmJjuUU28k7"
   },
   "outputs": [],
   "source": [
    "X_subset = X[['engine-size', 'make_audi']].values\n",
    "X_subset_modified = np.vstack((X_subset, [[1, 90], [2, 50]])) # добавление двух шумовых точек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jNZJOsJp28k9"
   },
   "outputs": [],
   "source": [
    "def scatter_points_and_plot_line_MSE(X_subset):\n",
    "    plt.scatter(X_subset[:, 0], X_subset[:, 1])   # визуализируем точки\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_subset[:, 0][:, np.newaxis], X_subset[:, 1])  # найдем веса линейной модели\n",
    "    grid = np.linspace(0, 2, 100)\n",
    "    line = lr.predict(grid[:, np.newaxis])\n",
    "    plt.plot(grid, line)   # визуализируем прямую"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "colab_type": "code",
    "id": "EurNOGcA28k_",
    "outputId": "91846eb5-0b08-40bb-f7dd-aeaa2501a6ac"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "scatter_points_and_plot_line_MSE(X_subset)\n",
    "plt.ylim(-20, 100)\n",
    "plt.xlabel('engine-size')\n",
    "plt.ylabel('make_audi')\n",
    "plt.subplot(1, 2, 2)\n",
    "scatter_points_and_plot_line_MSE(X_subset_modified)\n",
    "plt.ylim(-20, 100)\n",
    "plt.xlabel('engine-size')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oa7c8WRk28lC"
   },
   "source": [
    "Из-за шумовых объектов прямая достаточно сильно изменила наклон. Поэтому вместо MSE можно использовать Mean Absolute Error: $L(y_i, a(x_i)) = |a(x_i) - y_i|$:\n",
    "\n",
    "Теперь обучим регрессию, оптимизируя MAE. В sklearn такая регрессия не реализована, но для примера можно использовать модуль [statsmodels](https://www.statsmodels.org/stable/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PL2zqH8x28lD"
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BFTTYeqY28lF"
   },
   "outputs": [],
   "source": [
    "def scatter_points_and_plot_line_MAE(X_subset):\n",
    "    mod = smf.quantreg('f15 ~ f7', pd.DataFrame(data=X_subset, columns=[\"f7\", \"f15\"])) # задаеем зависимость и передаем данные\n",
    "    res = mod.fit(q=0.5)\n",
    "    plt.scatter(X_subset[:, 0], X_subset[:, 1])   # визуализируем точки\n",
    "    grid = np.linspace(0, 2, 100)\n",
    "    plt.plot(grid, grid * res.params[\"f7\"] + res.params[\"Intercept\"])   # визуализируем прямую\n",
    "    return mod, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 464
    },
    "colab_type": "code",
    "id": "ie_4TNdc28lH",
    "outputId": "605188d6-a1b5-4cfa-8636-05d4e7f654ae"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "model, result = scatter_points_and_plot_line_MAE(X_subset)\n",
    "plt.ylim(-20, 100)\n",
    "plt.xlabel('engine-size')\n",
    "plt.ylabel('make_audi')\n",
    "plt.subplot(1, 2, 2)\n",
    "model, result = scatter_points_and_plot_line_MAE(X_subset_modified)\n",
    "plt.ylim(-20, 100)\n",
    "plt.xlabel('engine-size')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AWlsyGfu28lK"
   },
   "source": [
    "Прямая не изменила направление из-за выбросов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E2doEVqJ28lL"
   },
   "source": [
    "Попробуем добавить больше шумовых объектов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RdDGJBER28lM"
   },
   "outputs": [],
   "source": [
    "np.random.seed(13)\n",
    "X_subset_modified_twice = np.vstack((X_subset_modified, np.random.randint(5, size=60).reshape(-1, 2)*[1, 30])) # добавление 30 шумовых точек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "colab_type": "code",
    "id": "McWJOOlN28lO",
    "outputId": "63c5686a-89c5-4be2-a6c5-dcd3a54b52e3"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "model, result = scatter_points_and_plot_line_MAE(X_subset)\n",
    "plt.ylim(-20, 100)\n",
    "plt.xlabel('engine-size')\n",
    "plt.ylabel('make_audi')\n",
    "plt.subplot(1, 2, 2)\n",
    "model, result = scatter_points_and_plot_line_MAE(X_subset_modified_twice)\n",
    "plt.ylim(-20, 100)\n",
    "plt.xlabel('engine-size')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sCq7zu_K28lQ"
   },
   "source": [
    "Прямая изменила наклон, когда мы добавили 30 (почти 15%) шумовых точек."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aMkNLdXE28lS"
   },
   "source": [
    "### Huber Loss\n",
    "Иногда используют Huber Loss - \"гибрид\" MAE и MSE, который, как и MAE, устойчив к шумовым объектам, и как и MSE, мало штрафует малые отклонения от фактического значения целевого признака:\n",
    "$$L(y_i, a(x_i)) = \\phi_\\varepsilon(a(x_i) - y_i)$$\n",
    "$$\\phi_\\varepsilon(z) = \\begin{cases} \\frac 1 2 z^2, - \\varepsilon < z < \\varepsilon, \\\\\\varepsilon (|z| - \\frac 1 2 \\varepsilon), иначе \\\\ \\end{cases}$$\n",
    "\n",
    "Оптимизация Huber Loss реализована в sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "63HdJ0fl28lT"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import HuberRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u5Yy3Ze228lV"
   },
   "source": [
    "### Quantile Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5vBaAgJJ28lW"
   },
   "source": [
    "В некоторых задачах штраф за ошибку зависит не только от величины абсолютного отклонения от фактического значения, но и от знака этого отклонения. Например, лучше предсказать спрос больше, чем будет по факту, чем меньше, потому что во втором случае будет потеряна прибыль. В этом случае используется квантильная регрессия со следующей функцией потерь:\n",
    "$$L(y_i, a(x_i)) = \\rho_\\tau(y_i - x_i^T w),$$\n",
    "$$\\rho_\\tau(z) = \\begin{cases} \\tau z, \\quad z > 0, \\\\ (\\tau - 1) z, \\quad z \\leqslant 0 \\end{cases}$$\n",
    "Параметр $\\tau \\in (0, 1)$ влияет на то, насколько различаются штрафы за положительную и отрицательную разницу.\n",
    "\n",
    "Изобразим график квантильной функции потерь вместе с другими рассмотренными:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "colab_type": "code",
    "id": "LZvF9yTL28lW",
    "outputId": "e50bf2a8-6567-4336-b110-1ff53b503344"
   },
   "outputs": [],
   "source": [
    "grid = np.linspace(-3, 3, 100)\n",
    "quantile_tau = 0.2\n",
    "mse_loss = grid ** 2\n",
    "mae_loss = np.abs(grid)\n",
    "huber_loss = 0.5 * mse_loss * (grid >= -1) * (grid <= 1) + (mae_loss - 0.5) * (grid < -1) + (mae_loss - 0.5)  * (grid > 1)\n",
    "quantile_loss = quantile_tau * grid * (grid > 0) + (quantile_tau - 1) * grid * (grid <= 0)\n",
    "plt.plot(grid, mae_loss, label=\"Absolute Loss\")\n",
    "plt.plot(grid, mse_loss, label=\"Quadratic Loss\")\n",
    "plt.plot(grid, huber_loss, label=\"Huber Loss\")\n",
    "plt.plot(grid, quantile_loss, label=\"Quantile Loss\")\n",
    "plt.xlabel(\"$y_i - a(x_i)$\")\n",
    "plt.ylabel(\"$L(y_i, a(x_i))$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r0dnqaQa28lZ"
   },
   "source": [
    "Проследим наклон прямой в нашей одномерной задаче регрессии при изменении $\\tau$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "id": "rq4LwwR728lZ",
    "outputId": "2a386590-ab1d-444c-c35b-39d20bb7085f"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X['engine-size'], y)\n",
    "grid = np.linspace(0, 2, 100)\n",
    "dat = pd.DataFrame({\"x\":X['engine-size'], \"y\":y})\n",
    "mod = smf.quantreg('y ~ x', dat)\n",
    "for q in np.arange(0.1, 1, 0.1):\n",
    "    res = mod.fit(q=q)\n",
    "    plt.plot(grid, grid * res.params[\"x\"] + res.params[\"Intercept\"], linewidth=0.5, label=\"q = \"+str(q))\n",
    "plt.legend(loc=(1.1, 0.1))\n",
    "plt.xlabel('engine-size')\n",
    "plt.ylabel('price')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "sem_linregr.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
